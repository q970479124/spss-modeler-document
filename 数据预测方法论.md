## 一、数据准备阶段 (3-5天) ##
### 本阶段目标： ###
在明确业务目标的基础上，完成目标数据的提取、清洗，为后续建模提供高质量输入数据   

1. **明确业务目标与问题定义：**
   > **说明：** 在数据准备之前，需要明确预测的业务场景、目标变量、样本对象及指标要求，以保证后续建模方向正确、可衡量  
   > **目的：** 确保数据准备阶段的工作围绕清晰的业务问题展开，避免后期重复调整或数据偏离

   - **确认预测目标：** 确定模型要预测的目标变量为 `素子数`
   - **确认预测业务对象：** 限定为电容型号 `03ENA` 和 `15XAW_GP`
   - **确认数据时间范围与量级：** 确认两个型号的数据是否覆盖最近 `3` 年，且样本量足够进行建模
   - **确认当前人工可达指标：** 例如当前人工预测 `ΔC` 的误差控制在 `2%` 以内
   - **设定预期目标指标：** 例如希望通过建模将 `ΔC` 误差降低 `20%`

2. **数据收集与整合：**
   > **说明：** 从客户数据库中获取目标型号的历史数据，并在 CP4D 平台中进行整合、可视化与初步分析，为后续清洗与特征工程提供基础   
   > **目的：** 确保所用数据一致、结构清晰，为后续清洗与特征工程提供基础

   - 使用 CP4D → 连接数据源节点 连接客户数据库
   - 在 Data Refinery 中编写 SQL，分别获取型号 03ENA 与 15XAW_GP 的数据
   - 利用 Data Refinery 可视化功能 生成探索性数据分析(EDA)报告，查看数据分布与质量
   - 在 SPSS Modeler 中使用「导入 → 数据资产节点」导入生成的数据资产
   - 使用「字段操作 → 类型节点」自动识别字段类型
   - 使用「输出 → 数据审计节点」生成并查看初步数据质量报告

3. **数据清洗(缺失值、异常值、重复值处理)：** 
   > **说明：** 对原始数据进行初步`(简单)`清洗，包括字段筛选、异常检测、缺失补全和重复值处理，确保数据质量基本满足建模需求  
   > **目的：** 提高数据完整性与一致性，剔除异常与噪声，保证输入数据的可靠性与可解释性

   - **质量审查：** 通过数据审计报告或 EDA 报告识别缺失值、异常值、重复记录及字段问题
   - **字段筛选：** 结合业务知识，使用「字段操作 → 过滤节点」去除无关或冗余字段
   - **缺失与异常处理：** 使用「字段操作 → 填充、派生、过滤节点」进行缺失值填补和异常值替换或删除
   - **重复与异常记录处理：** 使用「记录操作 → 选择、排序、总汇、合并节点」清除重复或异常记录
   - **结果验证：** 使用「输出 → 表 / 数据审计节点」生成清洗后数据质量报告，验证清洗效果

4. **特征命名规范化：**
   > **说明：** 统一数据字段命名规则，确保各字段在建模与结果解释中具有一致性与可读性  
   > **目的：** 提升数据可维护性与共享性，为特征工程、建模与后期可视化提供清晰结构  

   - 检查字段名称是否包含特殊符号或不一致命名
   - 按照统一规范(如英文字母+下划线命名)进行重命名
   - 若存在同义字段或业务重叠字段，进行合并与命名统一
   - 在字段属性中保留业务含义说明，方便后续追踪。

<br>

**阶段产出成果**  

| 分类     | 产出内容                                       |
| ------ | ------------------------------------------ |
| 明确目标   | 预测目标说明文档(素子数预测目标、指标定义、预期目标)                |
| 数据获取   | CP4D 数据连接与抽取 SQL 脚本、03ENA & 15XAW_GP 原始数据集 |
| 数据报告   | Data Refinery EDA 报告、SPSS 数据审计报告           |
| 数据清洗结果 | 清洗后高质量数据资产(含缺失/异常/重复处理)                    |
| 规范文档   | 字段命名规范及最终字段说明文档                            |

<br>

## 二、数据探索与理解 (7-10天) ##
### 本阶段目标： ###
系统地分析、可视化与理解清洗后的数据结构、分布与变量关系，识别潜在模式、异常值及关键特征，为后续建模和特征工程提供依据  
1. **描述性统计分析：**
   > **说明：** 对数据集进行基础统计分析，了解每个变量的总体特征，包括缺失情况、分布范围、集中趋势与离散程度  
   > **目的：** 掌握数据的总体概貌与分布规律，初步判断数据质量和变量可用性

   - 通过分析`探索性数据分析报告`或`数据审计报告`确定数据质量(例如缺失情况、最大/最小值、标准差、熵等信息)
   - 通过描述性统计确认数据是否存在极端值或明显错误
   - 初步评估后续数据清洗与特征工程的重点字段

2. **可视化探索(分布图、箱线图等)：**
   > **说明：** 利用可视化手段直观展示数据分布形态、偏态程度与异常点  
   > **目的：** 通过图形化展示快速识别数据规律、异常模式与分布特征，为特征工程提供直觉判断

   - **使用`探索性数据分析报告`的可视化功能查看：**
     - `直方图(Histogram)` 与 `Q–Q图(Quantile–Quantile Plot)`，判断是否服从正态分布
     - `箱线图(Boxplot)`，识别异常值分布及中位数位置
   - **重点检查：**
     - 分布是否偏斜
     - 是否存在极端离群值
     - 样本量是否平衡

3. **变量间相关性分析：**
   > **说明：** 通过统计与可视化手段分析变量之间的相关关系，识别潜在的共线性或依赖关系  
   > **目的：** 明确不同变量间的相关性结构，为后续特征筛选与模型输入变量选择提供依据

   - 在`探索性数据分析(EDA)报告` → 数据质量模块中查看：
     - `皮尔逊相关系数`、`斯皮尔曼相关系数`
     - 高相关(|r| > 0.8)的字段是否存在共线性
   - 使用可视化手段:
     - `散点图(Scatter Plot)` 分析变量关系
     - `热力图(Correlation Heatmap)` 查看整体相关矩阵
     - 观察异常点与峰值分布趋势

4. **异常点与离群值检测：**
   > **说明：** 对异常值、离群点及极端值进行系统检测与标注，评估其成因与对模型的影响  
   > **目的：** 识别并合理处理不符合总体规律的样本，避免建模时造成误导或过拟合  
   
   - 结合前几步的分布分析与箱线图结果，确定：
     - 异常值区间
     - 极值上下界
     - 离群点比例与位置
   - 根据业务与统计标准：
     - 删除明显错误记录
     - 或通过均值/中位数/插值法修正异常点
   - 在 SPSS Modeler 中可使用：
     - `数据审计节点`查看异常分布
     - `过滤节点`筛除异常样本
     - `派生节点`对异常值进行替换或标记

5. **变量重要性初步筛查：**
   > **说明：** 利用树模型(如随机森林、CHAID 或 C&R Tree)快速计算变量的重要性排序  
   > **目的：** 识别对目标变量(素子数)影响最大的特征字段，为后续特征工程和建模提供优先方向  
   
   - 使用 SPSS Modeler 的随机森林节点(或自动建模节点)进行初步预测
   - 通过`模型输出 → 特征重要性`报告获取各字段的重要性得分
   - 对得分较低、噪声高或冗余字段进行初步筛除
   - 输出特征重要性列表，作为建模阶段输入字段选择参考
  
**阶段产出成果**

| 分类      | 产出内容                   |
| ------- | ---------------------- |
| 描述性统计   | 各字段统计特征报告(均值、方差、缺失率、熵) |
| 可视化结果   | 分布图、Q–Q图、箱线图、散点图、热力图   |
| 变量相关性分析 | 相关矩阵与共线性报告             |
| 异常与离群检测 | 异常值检测报告及修正策略           |
| 变量重要性   | 初步特征重要性排序表             |

<br>

## 三、特征工程 (7-10天) ##
### 本阶段目标： ###
基于数据探索结果，构建、筛选并优化特征集合，生成对预测目标(素子数)最有信息量且能稳定泛化的特征集，为建模提供最终输入

1. **特征选择(过滤法、包裹法、嵌入法)：**
   > **说明：** 使用三类方法(Filter / Embedded / Wrapper)协同筛选特征，从统计相关性和模型重要性两个维度去除无关或冗余特征，保留高效特征  
   > **目的：** 降低维度、减少噪声和共线性、提升模型训练效率与泛化能力  

   - **过滤法(Filter) — 初筛：** 
     - 使用皮尔逊/斯皮尔曼相关系数、卡方、互信息等对每个特征与目标做评分
     - 删除与目标相关性极低(接近 0)或方差几乎为 0 的特征；合并或删除对目标同样高度相关且彼此高度相关(|r|>0.9)的字段，避免多重共线性
     - 产出：初筛特征列表与阈值说明(例如保留 |r|>0.05 的特征)
   - **嵌入法(Embedded) — 基于模型的重要性：**
     - 通过模型初步跑出数据重要性，保留高重要性数据和组合特征(参考`变量重要性初步筛查`)
     - 用随机森林、XGBoost、Lasso 等训练初版模型，导出特征重要性(feature importance)
     - 保留前 N 或累计重要性达到 X%(例如 95%)的特征，注意保留业务关键字段
     - 产出：模型重要性排名表，候选特征子集
   - **包裹法(Wrapper) — 精筛：** 使用模型进行递归验证和训练，不断追加或删除特征验证模型效果，多轮训练后总结出效果最佳的特征
     - 使用 RFE(递归特征消除)或向前/向后选择(Forward / Backward Selection)在目标建模器上评估特征子集(交叉验证下)
     - 以验证集/交叉验证的性能指标(如 RMSE、MAE、R²)为准，迭代决定最终特征集合
     - 产出：最终特征集合与每次迭代的性能对比表
**总结：** 初筛特征列表、相关性矩阵、候选特征子集、RFE 或包裹法的最终特征组合与对比结果

2. **特征构造(组合特征、统计特征等)：**
   > **说明：** 基于业务知识与数据分布构造新的有信息量的特征：比例/差值/交互项、滚动统计量、聚合统计(按设备/型号/批次)等  
   > **目的：** 提升模型表达力，捕捉非线性或交互关系，补强原始特征无法直接表示的业务模式  

   - **组合特征：** A/B、A×B、A−B、比率(如 电容某指标/温度)，以及分类字段交叉(如工艺×批次)
   - **统计特征(针对时序/多条记录设备)：** window rolling mean/std/max/min、历史累计值、最近 N 次平均、变化率(delta)
   - **聚合特征：** 按型号/批次/生产线聚合的统计量(平均ΔC、偏差、缺陷率等)
   - **标记型特征：** 阈值报警标志、异常标识(如是否超出 3σ)
   - **实践：** 优先构造少量高业务含义特征，先验证贡献再扩展；避免盲目高维交叉

3. **特征编码(One-Hot、Label Encoding 等)：**
   > **说明：** 对类别或有序特征进行编码，使其可用于不同模型(线性模型需数值输入，树模型可直接使用类别)  
   > **目的：** 保证模型能正确解释类别信息，同时控制维度膨胀  
   
   - 对高基数类别(类别数很大)优先做`频次编码/目标编码(target encoding)`或合并小类为`其他`，避免One-Hot爆炸
   - 对无序类别可One-Hot(若模型为线性/距离敏感)
   - 对有序类别用Label Encoding或映射数值
   - 树模型(随机森林/XGBoost)通常可直接输入类别(或经Label Encoding)，无需One-Hot
   - 在CP4D/SPSS Modeler中使用`字段操作 → 重新分类/派生节点`实现编码

4. **特征缩放(标准化、归一化等)：**
   > **说明：** 对特征做尺度变换(StandardScaler/MinMaxScaler/RobustScaler)，以满足某些模型/距离度量的要求  
   > **目的：** 提高模型收敛速度、避免某些特征主导模型(尤其对线性模型、KNN、SVM 等)  
   
   - 对线性模型、KNN、SVM、神经网络等必须做标准化(zero mean, unit variance)或归一化, 对树模型通常不必
   - 对含异常值的数据，优选RobustScaler(基于中位数与IQR)而非标准化
   - 在SPSS Modeler使用字段操作 → 派生节点做数值变换，保存变换参数(均值、方差)用于线上一致转换(部署阶段使用相同参数)
   - **重要：** 训练集计算scaler参数，测试/线上使用同一参数进行转换，避免数据泄露

5. **降维处理(PCA、LDA、ICA 等)：**
   > **说明：** 在高维或高度相关变量下，通过线性或非线性降维方法减少维数，同时保留主要信息  
   > **目的：** 减少维度、降低噪声、缓解共线性并提高训练速度  

   - 使用PCA提取主成分以保留X%方差(例如90–95%)
   - 在SPSS Modeler中使用建模 → PCA节点，并记录主成分变换矩阵(部署时需同样变换)
   - **注意：** 降维后的主成分往往可解释性差，适用于需要降维但不重视单变量解释的场景
   - 若使用LASSO/Embedding方法也可达到`隐式降维`的效果(通过稀疏化系数)

6. **特征重要性评估与优化(迭代)：**
   > **说明：** 将上述1–5步骤产生的特征在建模器上验证，通过交叉验证评估每次特征集的效果，并决定保留/删除/替换  
   > **目的：** 通过数据驱动的方式最终选出稳定且在验证集中表现最好的特征组合  
   - 将业务方验收指标(例如ΔC改善幅度)纳入评估维度，权衡可解释性与预测性能
   - **迭代次数：** 至少2–3轮主循环(构造→筛选→验证→优化)，每轮记录变更和性能对比
  
**产出**  
最终特征列表(含构造/编码/缩放信息)、每轮性能对比表、SHAP或特征解释报告

<br>

## 四、建模准备 (5-7天) ##
### 本阶段目标： ###
在清洗、特征工程完成后，构建模型训练所需的样本集结构，选择合适的算法类型及评估指标，为正式建模与验证做好技术准备  

1. **数据划分(训练集、验证集、测试集)：**
   > **说明：** 将数据集按比例划分为 训练集(Train)、验证集(Validation)、测试集(Test)，以支持模型训练、调参和最终性能评估, 通过交叉验证确保模型稳健性与泛化能力  
   > **目的：** 避免过拟合，保证模型在未见数据上的泛化能力，同时为多轮模型比较提供一致的验证框架  

   - 在SPSS Modeler → 字段操作 → 分区节点(Partition)中将样本随机划分：
     - 典型比例：训练集 70–80%，测试集 20–30%
     - 若样本量较大，可进一步细分出验证集(如 60% 训练 + 20% 验证 + 20% 测试)
   - 使用自动分类器(Auto Classifier)节点或自动建模(Auto Numeric)节点执行k折交叉验证(Cross Validation)：
     - 推荐 k=5 或 10
     - 每折训练时输出平均性能与标准差
   - 确保划分采用随机分区(Random Seed固定)，以保证结果可复现
     - 在多型号(如 03ENA、15XAW_GP)情况下，可分别划分并合并为独立建模流程

2. **模型选择：**
   > **说明：** 根据预测目标(数值型 → 回归问题)，选择候选模型，并通过多轮实验比较不同算法效果  
   > **目的：** 确定最适合数据特征、可解释性与业务需求的建模算法，为后续优化与部署打好基础  
   
   - **回归类任务(预测素子数)** 建议初步测试模型：
     - **线性模型：** 线性回归、岭回归、LASSO(检验线性可行性与特征重要性)
     - **非线性模型：** 决策树、随机森林、梯度提升树(GBM、XGBoost、CatBoost)
     - **神经网络/支持向量回归(SVR)：** 用于验证复杂非线性模式
   - **优先模型：**
     - 若数据维度高、存在非线性关系，梯度提升树(GBDT)通常效果较优
     - 可先验证 GBM 的精度是否达标，再视需求扩展至其他模型
   - **多模型训练：**
     - 使用`SPSS Modeler的自动建模(Auto Numeric Node)`一键比较多种模型
     - **对比指标：** R²、RMSE、MAPE、ΔC
     - 选出性能最优的模型类型与参数组合

3. **定义评价指标：**
   > **说明：** 确定用于评估模型训练与验证效果的标准化指标，结合业务需求与数据特性选定最终度量体系  
   > **目的：** 确保模型评估具备可量化、可比较、可追溯的标准，便于模型优化与业务验收

   - **建模阶段核心指标：**
     - **R²(决定系数)：** 衡量模型对目标的解释度
     - **RMSE(均方根误差)：** 反映预测误差的平均幅度
   - **测试/业务验证阶段指标：**
     - **MAPE(平均绝对百分比误差)：** 体现预测误差相对水平
     - **ΔC(目标业务指标误差)：** 体现模型在业务目标(如电容性能预测)上的达标率
   - 在SPSS Modeler → 输出 → 分析节点(Analysis)中查看模型预测分布与指标结果
   - 绘制预测值 vs 实际值散点图、误差分布图等，用于视觉化评估

**阶段产出**

| 产出内容     | 说明                          |
| -------- | --------------------------- |
| 评价指标定义文档 | 各指标计算公式、解释及使用阶段             |
| 模型评估报告   | 训练/验证/测试集的R²、RMSE、MAPE、ΔC结果 |
| 预测分布可视化  | 实际 vs 预测对比图、残差分布、误差箱线图      |

<br>

## 五、模型训练与评估 (5-7天) ##
1. 基础模型训练
   - 采用人工预测特征进行模型训练
   - 采用以上筛选出的特征进行模型训练

2. 参数调优
   - 树模型使用时采用超参数优化调整模型训练效果

3. 模型性能对比与筛选
   - 筛选出综合效果最佳的模型

4. 使用测试集/验证集评估性能
   - 通过spss modeler生成的模型查看模型结果
   - RMSE / MAPE / R² / ΔC 等指标计算
   - 误差分析：查看正态分布状况分析导致误差的原因
   - 多轮验证模型稳定性和鲁棒性(可能放在陪跑的模型运行阶段)

<br>

## 六、模型部署与监控 (3-5天) ##
### 本阶段目标： ###
将验证通过的模型正式部署到 Cloud Pak for Data (CP4D) 平台，实现在线或批量调用,同时建立模型监控与评估机制，确保模型在实际业务运行中保持稳定与高效性能。

1. **模型导出与上线(API、批处理、嵌入系统)**
   > **说明：** 将SPSS Modeler中训练完成且评估优良的模型导出，并部署到CP4D环境中，以便实现业务系统的实时调用(API)或批量预测处理  
   > **目的：** 实现模型的生产级应用与可访问性，使模型输出能直接支撑业务决策与自动化流程  
   - **模型导出与部署：**
     - 在 SPSS Modeler 中选中验证通过的模型节点
     - 通过`导出为模型资产`功能将模型发布到 CP4D
     - 在CP4D的AI管理模块(Watson Machine Learning)中确认部署状态
   - **API构建与测试：**
     - 在CP4D中为模型生成REST API接口
     - 使用代码调用API接口确认可用性
     - 验证输入输出格式、响应时间与预测准确性
   - **业务嵌入(嵌入生产系统)：**
     - 略

**阶段产出**

| 项目       | 内容                |
| -------- | ----------------- |
| 模型部署文档   | 模型导出步骤、部署路径及版本信息  |
| API 说明文档 | 接口地址、输入输出字段、调用示例  |
| 部署验证报告   | 调用成功率、响应时延、预测正确率等 |
| 系统集成结果   | 可视化调用界面或业务系统嵌入示例  |

<br>

2. **性能监控(漂移检测、精度监控)：**
   > **说明：** 对已上线模型进行持续性能跟踪与数据质量监控，确保模型在实际应用中持续保持稳定的预测能力。重点关注数据分布漂移(Data Drift)与模型性能下降(Model Decay)  
   > **目的：** 及时发现模型在生产环境中出现的性能衰退或数据分布异常，为模型再训练与版本更新提供依据，维持模型生命周期管理的闭环  
   - 模型上线运行阶段持续检测模型性能和精度
