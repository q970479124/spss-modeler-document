# 一、 什么是回归任务 #
> 用一些有用信息去预测一个 `连续型数值变量Y`
> 反过来说 已知的因素会对目标变量Y有多少影响（定量的估计每个因素对Y的影响大小）

从公式的角度出发：
> 有已知 因素X Z K J, 目标因素Y。 aX + bZ + cK + dJ = Y
> a b c d作为已知因素对Y影响的权重 → 说白了就是对Y影响了多少，哪个因素对Y影响多，哪个影响少。

与之相对的是分类任务、顾名思义 通过一些有用的信息将目标归类  

分类和回归的区别是：  
- 预测「这批零件是否合格」 → 分类任务  
- 预测「这个零件还能使用多久」 → 回归任务 

**回归任务的本质是通过数据抽象出其中的趋势**  
<br>
# 二、回归建模时可能遇到的误区 #
### 1. R²并不是越高越好 ###
- R² 高并不代表模型的泛化能力强，很可能只是对当前训练的拟合度高，数据变更后误差可能会被放大。`这叫做过拟合`  
- 看R²的同时要对比看 MAE/RMSE 以及测试集验证集的误差结果，MAE接近RMSE、训练集结果接近测试和验证集结果，这时才是一个好的模型。  
<br>

### 2. 特征不是越多越好 ###
- 特征的增多可能给模型带来噪声，让模型学习到虚假的趋势。  
- 对目标有影响的特征但是可能存在负提升，以及对目标无影响的特征都可能造成模型的不稳定。  
<br>

### 3. 相关性高并不表示一定重要 ###
- 相关性高可能存在共线性，说白了就是名字不同但含义相同，这种数据会导致模型无法正确区分各特征的真实贡献，使回归系数不稳定、可解释性变差，甚至预测结果在新数据上大幅波动。  
- 同时也存在伪相关性，即 A、B 两个因子只是分布趋势相同，但并不真正决定 Y，这会误导模型建立错误的 X→Y 关系，导致在新数据上预测失效。
<br>

### 4. 重要性低并不表示特征一定没有用 ###
- 重要性的解释与相关性类似，也存在多重共线性的影响。
- 比如某个特征在模型中的重要性为0，但它可能仍然具有明确的业务意义，只是因为与其他特征高度共线或被替代，导致其真实作用被模型吸收到了别的变量中。
<br>

### 5. 模型拟合并不一定是线性 ###
- 模型拟合的结果可能是非线性的，拟合的趋势而不是线段。  

### 6. 并不是预测准确就足够了 ###
- 对于生产中工程师可能会更关注可解释性，但是随着解释性的提高，预测的准确性会有所下降。  
- 投产过程中模型的稳定性同样至关重要，高稳定性带来的就是模型优秀的泛化能力。
- 噪声和模型的漂移也需要时刻关注，随着生产设备的老化或批次更新（环境的变化），会导致原有的 影响因子 → 预测目标 关系发生偏移，从而使模型逐渐失效，预测误差不断放大。  




